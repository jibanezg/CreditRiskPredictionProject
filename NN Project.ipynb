{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1974 - acc: 0.9347     \n",
      "Epoch 2/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1906 - acc: 0.9357     \n",
      "Epoch 3/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1892 - acc: 0.9363     \n",
      "Epoch 4/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1890 - acc: 0.9363     \n",
      "Epoch 5/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1883 - acc: 0.9364     \n",
      "Epoch 6/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1880 - acc: 0.9366     \n",
      "Epoch 7/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1876 - acc: 0.9368     \n",
      "Epoch 8/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1875 - acc: 0.9367     \n",
      "Epoch 9/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1874 - acc: 0.9367     \n",
      "Epoch 10/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1871 - acc: 0.9370     \n",
      "Epoch 11/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1869 - acc: 0.9367     \n",
      "Epoch 12/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1869 - acc: 0.9369     \n",
      "Epoch 13/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1867 - acc: 0.9369     \n",
      "Epoch 14/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1865 - acc: 0.9372     \n",
      "Epoch 15/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1864 - acc: 0.9372     \n",
      "12960/15001 [========================>.....] - ETA: 0sEpoch 1/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.2009 - acc: 0.9347     \n",
      "Epoch 2/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1909 - acc: 0.9359     \n",
      "Epoch 3/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1900 - acc: 0.9361     \n",
      "Epoch 4/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1893 - acc: 0.9360     \n",
      "Epoch 5/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1888 - acc: 0.9363     \n",
      "Epoch 6/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1891 - acc: 0.9363     \n",
      "Epoch 7/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1885 - acc: 0.9361     \n",
      "Epoch 8/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1884 - acc: 0.9363     \n",
      "Epoch 9/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1881 - acc: 0.9361     \n",
      "Epoch 10/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1878 - acc: 0.9366     \n",
      "Epoch 11/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1878 - acc: 0.9366     \n",
      "Epoch 12/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1875 - acc: 0.9366     \n",
      "Epoch 13/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1875 - acc: 0.9367     \n",
      "Epoch 14/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1873 - acc: 0.9370     \n",
      "Epoch 15/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1875 - acc: 0.9367     \n",
      "14352/15001 [===========================>..] - ETA: 0sEpoch 1/15\n",
      "134999/134999 [==============================] - 8s - loss: 0.1991 - acc: 0.9351     \n",
      "Epoch 2/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1906 - acc: 0.9356     \n",
      "Epoch 3/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1893 - acc: 0.9357     \n",
      "Epoch 4/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1888 - acc: 0.9357     \n",
      "Epoch 5/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1883 - acc: 0.9360     \n",
      "Epoch 6/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1879 - acc: 0.9361     \n",
      "Epoch 7/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1877 - acc: 0.9363     \n",
      "Epoch 8/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1874 - acc: 0.9361     \n",
      "Epoch 9/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1872 - acc: 0.9361     \n",
      "Epoch 10/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1869 - acc: 0.9364     \n",
      "Epoch 11/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1867 - acc: 0.9365     \n",
      "Epoch 12/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1868 - acc: 0.9365     \n",
      "Epoch 13/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1867 - acc: 0.9368     \n",
      "Epoch 14/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1868 - acc: 0.9367     \n",
      "Epoch 15/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1862 - acc: 0.9369     \n",
      "12432/15001 [=======================>......] - ETA: 0sEpoch 1/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1972 - acc: 0.9354     \n",
      "Epoch 2/15\n",
      "134999/134999 [==============================] - 8s - loss: 0.1901 - acc: 0.9364     \n",
      "Epoch 3/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1889 - acc: 0.9364     \n",
      "Epoch 4/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1885 - acc: 0.9365     \n",
      "Epoch 5/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1881 - acc: 0.9363     \n",
      "Epoch 6/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1877 - acc: 0.9363     \n",
      "Epoch 7/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1876 - acc: 0.9367     \n",
      "Epoch 8/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1874 - acc: 0.9362     \n",
      "Epoch 9/15\n",
      "134999/134999 [==============================] - 8s - loss: 0.1872 - acc: 0.9365     \n",
      "Epoch 10/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1871 - acc: 0.9367     \n",
      "Epoch 11/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1870 - acc: 0.9368     \n",
      "Epoch 12/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1867 - acc: 0.9365     \n",
      "Epoch 13/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1866 - acc: 0.9367     \n",
      "Epoch 14/15\n",
      "134999/134999 [==============================] - 7s - loss: 0.1866 - acc: 0.9364     \n",
      "Epoch 15/15\n",
      "134999/134999 [==============================] - 6s - loss: 0.1863 - acc: 0.9365     \n",
      "13120/15001 [=========================>....] - ETA: 0sEpoch 1/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1977 - acc: 0.9349     \n",
      "Epoch 2/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1899 - acc: 0.9357     \n",
      "Epoch 3/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1889 - acc: 0.9359     \n",
      "Epoch 4/15\n",
      "135000/135000 [==============================] - 7s - loss: 0.1882 - acc: 0.9364     \n",
      "Epoch 5/15\n",
      "135000/135000 [==============================] - 7s - loss: 0.1880 - acc: 0.9364     \n",
      "Epoch 6/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1878 - acc: 0.9363     \n",
      "Epoch 7/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1875 - acc: 0.9363     \n",
      "Epoch 8/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1876 - acc: 0.9365     \n",
      "Epoch 9/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1871 - acc: 0.9363     \n",
      "Epoch 10/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1870 - acc: 0.9365     \n",
      "Epoch 11/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1868 - acc: 0.9365     \n",
      "Epoch 12/15\n",
      "135000/135000 [==============================] - 7s - loss: 0.1869 - acc: 0.9365     \n",
      "Epoch 13/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1868 - acc: 0.9367     \n",
      "Epoch 14/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1867 - acc: 0.9365     \n",
      "Epoch 15/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1864 - acc: 0.9367     \n",
      "13296/15000 [=========================>....] - ETA: 0sEpoch 1/15\n",
      "135000/135000 [==============================] - 7s - loss: 0.1981 - acc: 0.9346     \n",
      "Epoch 2/15\n",
      "135000/135000 [==============================] - 8s - loss: 0.1906 - acc: 0.9356     \n",
      "Epoch 3/15\n",
      "135000/135000 [==============================] - 7s - loss: 0.1896 - acc: 0.9360     \n",
      "Epoch 4/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1892 - acc: 0.9359     \n",
      "Epoch 5/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1886 - acc: 0.9362     \n",
      "Epoch 6/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1881 - acc: 0.9364     \n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135000/135000 [==============================] - 7s - loss: 0.1881 - acc: 0.9365     \n",
      "Epoch 8/15\n",
      "135000/135000 [==============================] - 7s - loss: 0.1881 - acc: 0.9365     \n",
      "Epoch 9/15\n",
      "135000/135000 [==============================] - 8s - loss: 0.1876 - acc: 0.9365     \n",
      "Epoch 10/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1876 - acc: 0.9364     \n",
      "Epoch 11/15\n",
      "135000/135000 [==============================] - 7s - loss: 0.1876 - acc: 0.9363     \n",
      "Epoch 12/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1874 - acc: 0.9364     \n",
      "Epoch 13/15\n",
      "135000/135000 [==============================] - 7s - loss: 0.1873 - acc: 0.9366     \n",
      "Epoch 14/15\n",
      "135000/135000 [==============================] - 7s - loss: 0.1869 - acc: 0.9364     \n",
      "Epoch 15/15\n",
      "135000/135000 [==============================] - 6s - loss: 0.1868 - acc: 0.9365     \n",
      "14864/15000 [============================>.] - ETA: 0sEpoch 1/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.2007 - acc: 0.9347     \n",
      "Epoch 2/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1906 - acc: 0.9356     \n",
      "Epoch 3/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1895 - acc: 0.9358     \n",
      "Epoch 4/15\n",
      "135001/135001 [==============================] - 8s - loss: 0.1889 - acc: 0.9361     \n",
      "Epoch 5/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1884 - acc: 0.9364     \n",
      "Epoch 6/15\n",
      "135001/135001 [==============================] - ETA: 0s - loss: 0.1884 - acc: 0.936 - 9s - loss: 0.1883 - acc: 0.9364     \n",
      "Epoch 7/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1881 - acc: 0.9365     \n",
      "Epoch 8/15\n",
      "135001/135001 [==============================] - 9s - loss: 0.1881 - acc: 0.9365     \n",
      "Epoch 9/15\n",
      "135001/135001 [==============================] - 9s - loss: 0.1880 - acc: 0.9362     \n",
      "Epoch 10/15\n",
      "135001/135001 [==============================] - 8s - loss: 0.1876 - acc: 0.9364     \n",
      "Epoch 11/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1875 - acc: 0.9366     \n",
      "Epoch 12/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1875 - acc: 0.9365     \n",
      "Epoch 13/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1873 - acc: 0.9366     \n",
      "Epoch 14/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1869 - acc: 0.9367     \n",
      "Epoch 15/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1872 - acc: 0.9365     \n",
      "14080/14999 [===========================>..] - ETA: 0s-Epoch 1/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1997 - acc: 0.9352     \n",
      "Epoch 2/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1908 - acc: 0.9358     \n",
      "Epoch 3/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1898 - acc: 0.9359     \n",
      "Epoch 4/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1889 - acc: 0.9364     \n",
      "Epoch 5/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1882 - acc: 0.9367     \n",
      "Epoch 6/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1881 - acc: 0.9365     \n",
      "Epoch 7/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1878 - acc: 0.9367     \n",
      "Epoch 8/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1876 - acc: 0.9369     \n",
      "Epoch 9/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1875 - acc: 0.9368     \n",
      "Epoch 10/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1871 - acc: 0.9369     \n",
      "Epoch 11/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1872 - acc: 0.9369     \n",
      "Epoch 12/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1873 - acc: 0.9369     \n",
      "Epoch 13/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1869 - acc: 0.9368     \n",
      "Epoch 14/15\n",
      "135001/135001 [==============================] - 8s - loss: 0.1866 - acc: 0.9369     \n",
      "Epoch 15/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1867 - acc: 0.9371     \n",
      "13760/14999 [==========================>...] - ETA: 0sEpoch 1/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.2041 - acc: 0.9344     \n",
      "Epoch 2/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1904 - acc: 0.9361     \n",
      "Epoch 3/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1892 - acc: 0.9364     \n",
      "Epoch 4/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1888 - acc: 0.9363     \n",
      "Epoch 5/15\n",
      "135001/135001 [==============================] - 8s - loss: 0.1884 - acc: 0.9364     \n",
      "Epoch 6/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1880 - acc: 0.9366     \n",
      "Epoch 7/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1880 - acc: 0.9365     \n",
      "Epoch 8/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1876 - acc: 0.9365     \n",
      "Epoch 9/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1876 - acc: 0.9367     \n",
      "Epoch 10/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1875 - acc: 0.9366     \n",
      "Epoch 11/15\n",
      "135001/135001 [==============================] - 6s - loss: 0.1873 - acc: 0.9365     \n",
      "Epoch 12/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1873 - acc: 0.9366     \n",
      "Epoch 13/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1872 - acc: 0.9365     \n",
      "Epoch 14/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1869 - acc: 0.9371     \n",
      "Epoch 15/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1870 - acc: 0.9367     \n",
      "14768/14999 [============================>.] - ETA: 0sEpoch 1/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1972 - acc: 0.9340     \n",
      "Epoch 2/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1900 - acc: 0.9355     \n",
      "Epoch 3/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1891 - acc: 0.9358     \n",
      "Epoch 4/15\n",
      "135001/135001 [==============================] - 7s - loss: 0.1884 - acc: 0.9361     \n",
      "Epoch 5/15\n",
      "135001/135001 [==============================] - 9s - loss: 0.1879 - acc: 0.9362     \n",
      "Epoch 6/15\n",
      "135001/135001 [==============================] - 10s - loss: 0.1878 - acc: 0.9363    \n",
      "Epoch 7/15\n",
      "135001/135001 [==============================] - 8s - loss: 0.1876 - acc: 0.9364     \n",
      "Epoch 8/15\n",
      "135001/135001 [==============================] - 8s - loss: 0.1874 - acc: 0.9363     \n",
      "Epoch 9/15\n",
      "135001/135001 [==============================] - 8s - loss: 0.1872 - acc: 0.9364     \n",
      "Epoch 10/15\n",
      "135001/135001 [==============================] - 8s - loss: 0.1870 - acc: 0.9366     \n",
      "Epoch 11/15\n",
      "135001/135001 [==============================] - 9s - loss: 0.1869 - acc: 0.9362     \n",
      "Epoch 12/15\n",
      " 73008/135001 [===============>..............] - ETA: 3s - loss: 0.1853 - acc: 0.9373"
     ]
    }
   ],
   "source": [
    "import keras as ks\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "#import pandas_ml as pdml\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import norm, svd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "from sklearn.pipeline import Pipeline\n",
    "#from imblearn.under_sampling import ClusterCentroids                                                                 \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Random initialization\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "#function definition\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    #This function prints and plots the confusion matrix.\n",
    "    #Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def pcaAnalysis(X, lmbda=.01, tol=1e-3,maxiter=100, verbose=True):\n",
    "    \n",
    "    Y = X\n",
    "    norm_two = norm(Y.ravel(), 2)\n",
    "    norm_inf = norm(Y.ravel(), np.inf) / lmbda\n",
    "    dual_norm = np.max([norm_two, norm_inf])\n",
    "    Y = Y / dual_norm\n",
    "    A = np.zeros(Y.shape)\n",
    "    E = np.zeros(Y.shape)\n",
    "    dnorm = norm(X, 'fro')\n",
    "    mu = 1.25 / norm_two\n",
    "    rho = 1.5\n",
    "    sv = 10.\n",
    "    n = Y.shape[0]\n",
    "    itr = 0\n",
    "    while True:\n",
    "        Eraw = X - A + (1 / mu) * Y\n",
    "        Eupdate = np.maximum(Eraw - lmbda / mu, 0) + np.minimum(Eraw + lmbda / mu, 0)\n",
    "        U, S, V = svd(X - Eupdate + (1 / mu) * Y, full_matrices=False)\n",
    "        svp = (S > 1 / mu).shape[0]\n",
    "        if svp < sv:\n",
    "            sv = np.min([svp + 1, n])\n",
    "        else:\n",
    "            sv = np.min([svp + round(.05 * n), n])\n",
    "        Aupdate = np.dot(np.dot(U[:, :svp], np.diag(S[:svp] - 1 / mu)), V[:svp, :])\n",
    "        A = Aupdate\n",
    "        E = Eupdate\n",
    "        Z = X - A - E\n",
    "        Y = Y + mu * Z\n",
    "        mu = np.min([mu * rho, mu * 1e7])\n",
    "        itr += 1\n",
    "        if ((norm(Z, 'fro') / dnorm) < tol) or (itr >= maxiter):\n",
    "            break\n",
    "    if verbose:\n",
    "        print(\"Finished at iteration %d\" % (itr))  \n",
    "    return A, E\n",
    "\n",
    "def neural_network():\n",
    "    model = Sequential()\n",
    "    #model.add(Dropout(0.5, input_shape=(10,)))\n",
    "    model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    #model.fit(X_train, y_train, epochs=50, batch_size=10)\n",
    "    \n",
    "    return model\n",
    "\n",
    "#Initialization\n",
    "dataTrain = pd.read_csv('cs-training.csv').drop('Unnamed: 0', axis = 1)\n",
    "dataTest = pd.read_csv('cs-test.csv').drop('Unnamed: 0', axis = 1)\n",
    "\n",
    "targetTrain = dataTrain['SeriousDlqin2yrs']\n",
    "targetTest = dataTest['SeriousDlqin2yrs']\n",
    "\n",
    "dataTrain = dataTrain.drop(['SeriousDlqin2yrs'],axis=1)\n",
    "dataTest = dataTest.drop(['SeriousDlqin2yrs'],axis=1)\n",
    "\n",
    "\n",
    "#Preprocessing\n",
    "\n",
    "dataTrain = dataTrain.fillna(0.0)\n",
    "dataTest = dataTest.fillna(0.0)\n",
    "\n",
    "#sampler = ClusterCentroids(ratio='majority', random_state=42, n_jobs=-1) \n",
    "#dataTrain = sampler.fit_sample(dataTrain,targetTrain)\n",
    "#print(dataTrain.target.value_counts())\n",
    "#scaler = StandardScaler()\n",
    "#dataTrainNormalized = scaler.fit_transform(dataTrain)\n",
    "#dataTestNormalized = scaler.fit_transform(dataTest)\n",
    "\n",
    "#PCA\n",
    "#dataTrainPCA = np.array(dataTrainNormalized)\n",
    "#dataTestPCA = np.array(dataTestNormalized)\n",
    "\n",
    "#pca = PCA(n_components=8)\n",
    "#pca.fit(dataTrainPCA)\n",
    "#PCA(copy=True, iterated_power='auto', n_components=1, random_state=None,\n",
    "#  svd_solver='auto', tol=0.0, whiten=False)\n",
    "\n",
    "#print(pca.transform(dataTrainPCA))\n",
    "#print(dataTrainPCA)\n",
    "#print(dataTestPCA)\n",
    "#print(np.shape(dataTestPCA))\n",
    "#print(np.shape(dataTrainPCA))\n",
    "#sz = 8\n",
    "#C, D = pcaAnalysis(dataTrainPCA[:,:sz])\n",
    "#dataTrainPCA = C+D\n",
    "#C, D = pcaAnalysis(dataTestPCA[:,:sz])\n",
    "#dataTestPCA = C+D\n",
    "#print(np.shape(dataTestPCA))\n",
    "#print(np.shape(dataTrainPCA))\n",
    "#print(np.shape(dataTestPCA))\n",
    "#print(np.shape(dataTestPCA))\n",
    "\n",
    "#Cross validation data split\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(dataTrainNormalized, targetTrain, test_size=0.4, random_state=0)\n",
    "\n",
    "#K fold validation\n",
    "#from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import model_selection\n",
    "\n",
    "#kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "# Neural Net Dropout\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=neural_network, epochs=15, batch_size=16, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "scores = cross_val_predict(pipeline, dataTrain, targetTrain, cv=kfold)\n",
    "#scores = model.evaluate(X_train, y_train)\n",
    "cnf_matrix = confusion_matrix(targetTrain,scores)\n",
    "np.set_printoptions(precision=2)\n",
    "class_names= ['No Risk','Risk']\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
